{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "216bfca4-dc8a-4ab8-b033-41af4f61089c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  \n",
    "# The Travelling Salesman Problem\n",
    "\n",
    "<br />\n",
    "\n",
    "Colin Valentini & Su Hang\n",
    "\n",
    "November 11, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ec2c4b4a-173d-4edd-84d2-f5c3331e59be"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "- What is the Travelling Salesman Problem (TSP)?\n",
    "- Why do we care? Why should *you* care?\n",
    "- Bibliography\n",
    "- Solutions vs. heuristics\n",
    "- Lin-Kernighan Heuristics et al.\n",
    "    - Standard, Mak & Morton, Chained LK\n",
    "- The Ant Colony System\n",
    "- Demo\n",
    "- The Future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ee0c8189-1595-4ba7-b762-23d381c7ff4c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is the Travelling Salesman Problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Given a set of cities, what's the fastest way to visit each city exactly once and then return home?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Complete (di)graph $G = (V, E)$\n",
    "\n",
    "**Cities**\n",
    "$$V = \\{v_i\\}_{i=1}^n$$\n",
    "\n",
    "**Paths between each possible city pair**\n",
    "\n",
    "\\begin{align}\n",
    "E &= \\{e_j\\}_{j=1}^m \n",
    "\\\\\n",
    "m &=\n",
    "\\begin{cases}\n",
    "\\frac{n (n-1)}{2} & \\text{symmetric TSP, undirected edges} \\\\\n",
    "n (n-1) & \\text{asymmetric TSP, directed edges}\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "**Cost vector**\n",
    "\n",
    "\\begin{align}\n",
    "c &\\in \\mathbb{R}^m \\\\\n",
    "m &=\n",
    "\\begin{cases}\n",
    "c_{ab} = c_{ba}  & \\text{symmetric TSP, undirected edges} \\\\\n",
    "c_{ab} \\neq c_{ba} & \\text{asymmetric TSP, directed edges}\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Today, we restrict ourselves to the **symmetric** case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "611b9d1e-b0fb-458b-9374-36fcf46b6d67"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Tour vectors**\n",
    "\n",
    "$$\\mathbf{x} \\in \\{0,1\\}^m\n",
    "\\quad\\text{where }\n",
    "x_{j} =\n",
    "\\begin{cases}\n",
    "1 & e_j \\text{ in tour} \\\\\n",
    "0 & e_j \\text{ not in tour}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**All possible tour vectors**\n",
    "\n",
    "$$\\mathbf{x} \\in S \\quad \\text{and} \\quad |S| = (n-1)!$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Objective function**\n",
    "$$\n",
    "\\underset{\\mathbf{x} \\in S}{\\arg\\min} ~ \\mathbf{c}^\\top \\mathbf{x}\n",
    "$$\n",
    "\n",
    "such that\n",
    "\n",
    "1. Each city $v$ participates in 2 edges\n",
    "\n",
    "$$\n",
    "\\sum_{j: v \\in e_j} x_j = 2 \\quad \\forall \\, \\mathbf{x} \\in S\n",
    "$$\n",
    "\n",
    "2. ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do we care?\n",
    "\n",
    "Colin\n",
    "    - \n",
    "\n",
    "Su\n",
    "- Also a CS Major in Intelligent Systems track\n",
    "- Part of research is on reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why should *you* care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"http://imgs.xkcd.com/comics/travelling_salesman_problem.png\" width=800 /></center>\n",
    "\n",
    "Source: xkcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bae50cbd-613d-421a-b078-e162230bfc9a"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Encryption\n",
    "$$\n",
    "P \\overset{?}{=} NP\n",
    "$$\n",
    "\n",
    "#### Operations Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solutions vs. Heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "As it relates to P?=NP\n",
    "\n",
    "e.g. (non-)convexity, and the power of \"good enough\" in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bibliography\n",
    "\n",
    "<br />\n",
    "\n",
    "<div style=\"font-size: 0.65em\">\n",
    "\n",
    "Applegate, D., R. Bixby, V. Chv√°tal, W. Cook. 2006. The Travelling Salesman Problem: A Computational Study. Princeton, New Jersey.\n",
    "\n",
    "Deneubourg, J-L., et al. \"The self-organizing exploratory pattern of the Argentine ant.\" Journal of insect behavior 3.2 (1990): 159-168.\n",
    "\n",
    "Perna, Andrea, et al. \"Individual rules for trail pattern formation in Argentine ants (Linepithema humile).\" PLoS Comput Biol 8.7 (2012): e1002592.\n",
    "\n",
    "Dorigo, Marco, and Luca Maria Gambardella. \"Ant colony system: a cooperative learning approach to the traveling salesman problem.\" IEEE Transactions on evolutionary computation 1.1 (1997): 53-66.\n",
    "\n",
    "Lin, Shen, and Brian W. Kernighan. \"An effective heuristic algorithm for the traveling-salesman problem.\" Operations research 21.2 (1973): 498-516.\n",
    "\n",
    "Mak K., A. Morton. 1993. A modified Lin-Kernighan traveling-salesman heuristic.  Operations Research Letters 13, 127-132.\n",
    "\n",
    "Martin, O., S. Otto, E. Felten. 1991. Large-step Markov chains for the traveling salesman problem. Complex Systems 5, 299-326.\n",
    "\n",
    "Rosenkrantz, Daniel J., Richard E. Stearns, and Philip M. Lewis, II. \"An analysis of several heuristics for the traveling salesman problem.\" SIAM journal on computing 6.3 (1977): 563-581.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Lin-Kernighan Heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overview\n",
    "\n",
    "The Lin-Kernighan Heuristic (LK-H) is one of the most popular TSP heuristics\n",
    "\n",
    "1973, Bell Labs, by Shen Lin and Brian Kernighan\n",
    "\n",
    "Dominant heuristic approach for 15 years\n",
    "\n",
    "Most modern heuristics have LK-H at their core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "82a1675c-a101-4204-b5d2-5a2cb0029073"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Fun Facts\n",
    "\n",
    "Kernighan also co-authored *the* book on C, The C Programming Language Manual\n",
    "\n",
    "Also co-created the AWK programming language with Prof. Alfred Aho (of Columbia CS Theory and \"Dragon Book\" fame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How does LK-H work?\n",
    "\n",
    "Can we find a set of $k$ edges in a given tour $T$ and replace them with another set of $k$ edges not in $T$ to get a tour with less cost?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### k-Optimality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "\\<img src=\"fig/mak_and_morton_lkh.png\" width=800 /></center>\n",
    "[Mak and Morton, 1991]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode for the Lin-Kernighan Heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivatives of the Lin-Kernighan Heuristic\n",
    "\n",
    "Chained Lin-Kernighan [Martin and Felten, 1991]\n",
    "\n",
    "**Modified Lin-Kernighan [Mak and Morton, 1991]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"float: left; margin-top:15%\" src=\"fig/mak_and_morton_sym.png\" width=500 />\n",
    "<img style=\"float: right;\" src=\"fig/mak_and_morton_mlk.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "[Mak and Morton, 1993]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Ant Colony System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](fig/deneubourg_1989_no_food.png)\n",
    "\\[Deneubourg, 1989\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "savage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"fig/deneubourg_1989_diamond.png\" width=800 /></center>\n",
    "[Deneubourg, 1989]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><iframe width=\"800\" height=\"600\" src=\"https://www.youtube.com/embed/gPK4Oi2x0mQ\" frameborder=\"0\" allowfullscreen></iframe></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<center><iframe width=\"800\" height=\"600\" src=\"https://www.youtube.com/embed/gPK4Oi2x0mQ\" frameborder=\"0\" allowfullscreen></iframe></center>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network of exploratory trails in Argentine ants (short) by SwarmLabNJIT on YouTube\n",
    "\n",
    "[Perna et al., 2012]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\"In this video, you can see the formation of a network of pheromone trails by Argentine ants freely exploring an empty circular arena (1m diameter) for 1 hour. The ants enter the arena from the its center.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making your own exploring ant colony: a step by step guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 1: Initialise\n",
    "\n",
    "Scatter ants around graph randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 2: Tour Building\n",
    "\n",
    "Have each ant complete a tour.\n",
    "\n",
    "How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### State transition rule\n",
    "\n",
    "Ants decide their next step based on\n",
    "\n",
    "- cost of edges\n",
    "- pheromones on edges\n",
    "- chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### Local updates\n",
    "\n",
    "Pheromones on edges change on ant traversal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Repeat until each ant has completed a tour at time $n - 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 3: Sprint retrospective\n",
    "\n",
    "After each ant has built a tour for this round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### Global Updates\n",
    "\n",
    "Update pheromones based on the best tour in all rounds so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 4: Iterate. Pray. Profit.\n",
    "\n",
    "Lather, rinse, repeat steps 1-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When to stop?\n",
    "\n",
    "- No improvements in tour length for a couple of rounds, or\n",
    "- Exceeded a preset number of rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Solution\n",
    "\n",
    "Best tour ever found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### All together now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Once more, with Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Send $m$ ants out into the world to find a Hamiltonian path (i.e. a tour) between $n$ nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In each iteration, each ant completes a tour over times $j \\in \\{ 0, 1, 2, \\ldots n - 1 \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Repeat for multiple iterations $i \\in I$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 1: Initialise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $X_j^{(k)}$ be the node ant $k$ is at time $j \\in 0, 1, 2, \\ldots, n - 1$ for the present iteration\n",
    "\n",
    "Choose a random starting position for each ant:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\left\\{X_0^{(k)}\\right\\}_{k=1}^m \\sim \\text{Multinomial} \\left( \\left\\{\\frac{1}{|N|} \\right\\}_{n \\in N}, m \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 2: Tour Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### State transition rule\n",
    "\n",
    "aka how does an ant choose the next node to visit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Key Idea* Exploration vs. Exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Introduce tuning parameter $q_0 \\in [0,1]$ and $q \\sim \\mathcal{U}(0,1)$ such that\n",
    "\n",
    "$$\n",
    "\\text{Next Action} =\n",
    "\\begin{cases}\n",
    "\\text{Exploitation} & q \\leq q_0\\\\\n",
    "\\text{(Biased) Exploration} & q > q_0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$q_0 = 0.9$ in Dorigo & Gambardella, 1997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Specifically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\delta(r,s)$ the cost of traversing the edge from node $r$ to node $s$\n",
    "\n",
    "$\\tau(r,s)$ the amount of pheromone on the edge connecting node $r$ to node $s$\n",
    "\n",
    "$\\beta > 0$ a parameter for the relative importances of cost $\\delta(r,s)$ and pheromone $\\tau(r,s)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Define a **desirability score** for the edge from node $a$ to node $b$\n",
    "\n",
    "$$\n",
    "\\Psi (a, b) := \\frac{ \\tau \\left( a, b \\right) }{ \\left[ \\delta \\left( a, b \\right) \\right]^\\beta }\n",
    "$$\n",
    "\n",
    "$\\beta = 2$ in Dorigo & Gambardella, 1997."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Also define $U_{j}^{(k)}$, the set of unvisited nodes for ant $k$ at time $j$.\n",
    "\n",
    "If $q \\leq q_0$, the ant (deterministically) exploits what the colony has learnt\n",
    "\n",
    "$$\n",
    "X_{j+1}^{(k)} = \\underset{u \\in U_{j}^{(k)}}{\\arg\\max} ~ \\Psi \\left( X_{j}^{(k)}\\!, u \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Else $q > q_0$ and the ant decides to do some exploration\n",
    "\n",
    "$$\n",
    "\\mathbb{P} \\left[ X_{j+1}^{(k)} = u \\right] =\n",
    "\\begin{cases}\n",
    "\\frac{\\Psi \\left( X_j^{(k)}, ~ u \\right)}{\\sum_{v \\in U_{j}^{(k)}} \\Psi \\left( X_j^{(k)}, ~ v \\right) } & u \\in U_{j}^{(k)} \\\\\n",
    "0 & u \\not\\in U_{j}^{(k)}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Local update rule\n",
    "\n",
    "aka how does an ant change $\\tau(a,b)$ as they traverse $(a,b)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So-named because this is the update rule for single edges as the ants are building their tours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\tau (a,b) \\leftarrow (1 - \\rho) \\, \\tau (a, b) + \\rho \\, \\tau_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\rho \\in (0,1)$ a parameter representing the pheromone erosion rate; $\\rho = 0.1$ in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\tau_0$ the initial value of $\\tau(a,b)$, at round 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\tau_0 = \\frac{1}{n L_\\text{NN}}$ where $L_\\text{NN}$ is the tour length found by the nearest neighbours heuristic [Dorigo & Gambardella, 1997]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$L_\\text{NN}$ is supposed to represent a very rough approximation of tour length. $\\tau_0$ was obtained empirically in the paper and it wasn't explained why this is the optimal amount of pheromone to start with.\n",
    "\n",
    "Local update rule has the form of exponential smoothing\n",
    "\n",
    "Why erosion? Helps with promoting exploration. Edges with high tau at start of round will get eroded over time since it's more probable they'll be selected first, giving the low tau edges a chance to be explored once the high tau edges have been eroded enough. No erosion => easy trapping into local optima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Local update rule\n",
    "\n",
    "aka how does an ant change $\\tau(a,b)$ as they traverse $(a,b)$?\n",
    "\n",
    "Interesting variant using Q-learning\n",
    "\n",
    "$$\n",
    "\\tau \\left( X_j^{(k)} , ~ X_{j+1}^{(k)} \\right) \\leftarrow (1 - \\rho) ~ \\tau \\left( X_j^{(k)} , ~ X_{j+1}^{(k)} \\right) + \\rho \\max_{u \\in U_{j+1}^{(k)}} \\tau \\left( X_{j+1}^{(k)}, ~ u \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Q-learning: reinforcement learning by recursive application of the above exponential smoothing-like rule, but with \"discounted evaluation\" of the next state's value\n",
    "\n",
    "i.e. the larger the potential tau in the next state, the larger the update.\n",
    "\n",
    "Why interesting? Authors found that this rule worked about as well as the erosion rule we saw before, at greater computational cost. Would expect that taking into account future actions would help in getting good solution faster (because more exploitation), but apparently exploration wins out over exploitation here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 3: Sprint retrospective\n",
    "\n",
    "After each ant has completed their tour for the round, look back on the tours found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Global Updates\n",
    "\n",
    "aka how does the colony reinforce good solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\tau (a,b) \\leftarrow\n",
    "\\begin{cases}\n",
    "(1 - \\alpha) \\, \\tau (a, b) + \\frac{\\alpha}{L_\\text{GB}} & (a,b) \\in \\text{global best tour} \\\\\n",
    "(1 - \\alpha) \\, \\tau (a, b) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\alpha \\in (0,1)$ the pheromone decay parameter; $\\alpha = 0.1$ in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Again with the exponential smoothing form\n",
    "\n",
    "global best: best tour found in all rounds so far.\n",
    "\n",
    "shorter tours => more pheromone. reinforces short tours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9e635211-09e2-4c58-a9a5-385a556e2326"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Future\n",
    "\n",
    "Colin\n",
    "\n",
    "**Su** Industry for a few years, and then maybe grad school in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "04fce4b3-ce71-42ac-b491-6518340e5a4c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {
    "12890c14-6c99-4be1-85dd-a1bfef870ad3": {
     "id": "12890c14-6c99-4be1-85dd-a1bfef870ad3",
     "prev": "479784d7-e41c-4468-b7b4-0f3bd041e128",
     "regions": {
      "dccd8419-bf50-403c-a4a2-785d5a7d265c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "82a1675c-a101-4204-b5d2-5a2cb0029073",
        "part": "whole"
       },
       "id": "dccd8419-bf50-403c-a4a2-785d5a7d265c"
      }
     }
    },
    "13e6b623-ec06-49e2-8258-b3baa62debb9": {
     "id": "13e6b623-ec06-49e2-8258-b3baa62debb9",
     "prev": "1ccdf986-3b48-437e-a4b1-9ce83a1a7d5f",
     "regions": {
      "2b495cf7-22c1-4e29-92b1-da9fcc7376c3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9e635211-09e2-4c58-a9a5-385a556e2326",
        "part": "whole"
       },
       "id": "2b495cf7-22c1-4e29-92b1-da9fcc7376c3"
      }
     }
    },
    "14476b40-fb13-4d21-9c0c-716c0dba509e": {
     "id": "14476b40-fb13-4d21-9c0c-716c0dba509e",
     "prev": "2113ad9c-9954-447b-b7c9-788dded1ed3f",
     "regions": {
      "73932159-ee19-44e5-964c-b6c7bfc35670": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bae50cbd-613d-421a-b078-e162230bfc9a",
        "part": "whole"
       },
       "id": "73932159-ee19-44e5-964c-b6c7bfc35670"
      }
     }
    },
    "1ccdf986-3b48-437e-a4b1-9ce83a1a7d5f": {
     "id": "1ccdf986-3b48-437e-a4b1-9ce83a1a7d5f",
     "prev": "f5dd3dbc-55dd-4875-a3e7-1b6fd4bcc51e",
     "regions": {
      "7bc30fff-b5bf-448b-8fbc-4c93874d4310": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7fec18c4-7124-41fd-815d-c4fb44b10893",
        "part": "whole"
       },
       "id": "7bc30fff-b5bf-448b-8fbc-4c93874d4310"
      }
     }
    },
    "2113ad9c-9954-447b-b7c9-788dded1ed3f": {
     "id": "2113ad9c-9954-447b-b7c9-788dded1ed3f",
     "prev": "7ca3c787-3801-41f4-984b-22b92fadb7f6",
     "regions": {
      "dca8a725-1771-4f8c-ae54-a8fe55f31712": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ee0c8189-1595-4ba7-b762-23d381c7ff4c",
        "part": "whole"
       },
       "id": "dca8a725-1771-4f8c-ae54-a8fe55f31712"
      }
     }
    },
    "2c6858ff-e371-4f0c-8255-f0bfb29c3b68": {
     "id": "2c6858ff-e371-4f0c-8255-f0bfb29c3b68",
     "prev": "12890c14-6c99-4be1-85dd-a1bfef870ad3",
     "regions": {
      "33848413-3926-42b2-995b-33f3eede2719": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "58929e69-7915-4d21-80eb-281c09ed8a22",
        "part": "whole"
       },
       "id": "33848413-3926-42b2-995b-33f3eede2719"
      }
     }
    },
    "479784d7-e41c-4468-b7b4-0f3bd041e128": {
     "id": "479784d7-e41c-4468-b7b4-0f3bd041e128",
     "prev": "fa2cbb61-3106-46bc-b6d8-e6ccf4ff0893",
     "regions": {
      "5eb38664-0108-4252-82ec-911318bc46d3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bff6b21b-625e-46d9-8039-2df6ad5a058d",
        "part": "whole"
       },
       "id": "5eb38664-0108-4252-82ec-911318bc46d3"
      }
     }
    },
    "7ca3c787-3801-41f4-984b-22b92fadb7f6": {
     "id": "7ca3c787-3801-41f4-984b-22b92fadb7f6",
     "prev": "a0adc573-c600-4b42-afa3-ae30fb4fa555",
     "regions": {
      "76c26bd2-e668-46b6-90cd-39b5194f604e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ec2c4b4a-173d-4edd-84d2-f5c3331e59be",
        "part": "whole"
       },
       "id": "76c26bd2-e668-46b6-90cd-39b5194f604e"
      }
     }
    },
    "856e558e-159c-460e-8365-625e33dca104": {
     "id": "856e558e-159c-460e-8365-625e33dca104",
     "prev": "13e6b623-ec06-49e2-8258-b3baa62debb9",
     "regions": {
      "4172f925-8324-478d-bbac-566af5a15601": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "04fce4b3-ce71-42ac-b491-6518340e5a4c",
        "part": "whole"
       },
       "id": "4172f925-8324-478d-bbac-566af5a15601"
      }
     }
    },
    "a0adc573-c600-4b42-afa3-ae30fb4fa555": {
     "id": "a0adc573-c600-4b42-afa3-ae30fb4fa555",
     "prev": null,
     "regions": {
      "647759a6-e14e-4403-b547-34b390a77447": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "216bfca4-dc8a-4ab8-b033-41af4f61089c",
        "part": "whole"
       },
       "id": "647759a6-e14e-4403-b547-34b390a77447"
      }
     },
     "theme": null
    },
    "f5dd3dbc-55dd-4875-a3e7-1b6fd4bcc51e": {
     "id": "f5dd3dbc-55dd-4875-a3e7-1b6fd4bcc51e",
     "prev": "2c6858ff-e371-4f0c-8255-f0bfb29c3b68",
     "regions": {
      "26a4917a-df08-4b09-8fba-202989d2680b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e6e7980b-d71f-4bc2-8607-c5342bbae3d2",
        "part": "whole"
       },
       "id": "26a4917a-df08-4b09-8fba-202989d2680b"
      }
     }
    },
    "fa2cbb61-3106-46bc-b6d8-e6ccf4ff0893": {
     "id": "fa2cbb61-3106-46bc-b6d8-e6ccf4ff0893",
     "prev": "14476b40-fb13-4d21-9c0c-716c0dba509e",
     "regions": {
      "14dbea4b-aaf4-485b-9f9e-a602690f115a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "611b9d1e-b0fb-458b-9374-36fcf46b6d67",
        "part": "whole"
       },
       "id": "14dbea4b-aaf4-485b-9f9e-a602690f115a"
      }
     }
    }
   },
   "themes": {
    "default": "90192edb-6e5c-40a3-9edb-4c57a32286e5",
    "theme": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
